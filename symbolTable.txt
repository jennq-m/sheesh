Lexical Analysis of test.shs:

Line 1: Lexeme: //              Token: Comment
Line 2: Lexeme: =               Token: Operator
Line 3: Lexeme: hello           Token: Identifier
Line 3: Lexeme: hello           Token: Identifier
Line 4: Lexeme: +=              Token: Operator
Line 5: Lexeme: -=              Token: Operator
Line 6: Lexeme: *=              Token: Operator
Line 7: Lexeme: /=              Token: Operator
Line 8: Lexeme: %=              Token: Operator
Line 10: Lexeme: //              Token: Comment
Line 11: Lexeme: &&              Token: Operator
Line 12: Lexeme: ||              Token: Operator
Line 13: Lexeme: !               Token: Operator
Line 15: Lexeme: //              Token: Comment
Line 16: Lexeme: +               Token: Operator
Line 17: Lexeme: -               Token: Operator
Line 18: Lexeme: *               Token: Operator
Line 19: Lexeme: /               Token: Operator
Line 20: Lexeme: %               Token: Operator
Line 22: Lexeme: //              Token: Comment
Line 23: Lexeme: +               Token: Operator
Line 24: Lexeme: -               Token: Operator
Line 25: Lexeme: ++              Token: Operator
Line 26: Lexeme: --              Token: Operator
Line 28: Lexeme: //              Token: Comment
Line 29: Lexeme: ==              Token: Operator
Line 30: Lexeme: !=              Token: Operator
Line 31: Lexeme: >               Token: Operator
Line 32: Lexeme: <               Token: Operator
Line 33: Lexeme: >=              Token: Operator
Line 34: Lexeme: <=              Token: Operator
Line 36: Lexeme: //              Token: Comment
Line 37: Lexeme: bounce          Token: Keyword
Line 38: Lexeme: car             Token: Keyword
Line 39: Lexeme: do              Token: Keyword
Line 40: Lexeme: drift           Token: Keyword
Line 41: Lexeme: empty           Token: Keyword
Line 42: Lexeme: ex              Token: Keyword
Line 43: Lexeme: flip            Token: Keyword
Line 44: Lexeme: frozen          Token: Keyword
Line 45: Lexeme: group           Token: Keyword
Line 46: Lexeme: iffy            Token: Keyword
Line 47: Lexeme: input           Token: Keyword
Line 48: Lexeme: jump            Token: Keyword
Line 49: Lexeme: legit           Token: Keyword
Line 50: Lexeme: locked          Token: Keyword
Line 51: Lexeme: lockin          Token: Keyword
Line 52: Lexeme: long            Token: Keyword
Line 53: Lexeme: meanwhile       Token: Keyword
Line 54: Lexeme: nickname        Token: Keyword
Line 55: Lexeme: num             Token: Keyword
Line 56: Lexeme: open            Token: Keyword
Line 57: Lexeme: other           Token: Keyword
Line 58: Lexeme: out             Token: Keyword
Line 59: Lexeme: outside         Token: Keyword
Line 60: Lexeme: pl              Token: Keyword
Line 61: Lexeme: rep             Token: Keyword
Line 62: Lexeme: scenario        Token: Keyword
Line 63: Lexeme: short           Token: Keyword
Line 64: Lexeme: standard        Token: Keyword
Line 65: Lexeme: stop            Token: Keyword
Line 66: Lexeme: team            Token: Keyword
Line 67: Lexeme: text            Token: Keyword
Line 68: Lexeme: vibe            Token: Keyword
Line 70: Lexeme: //              Token: Comment
Line 71: Lexeme: always          Token: Reserved Word
Line 72: Lexeme: cap             Token: Reserved Word
Line 73: Lexeme: cont            Token: Reserved Word
Line 74: Lexeme: nocap           Token: Reserved Word
Line 75: Lexeme: toptier         Token: Reserved Word
Line 77: Lexeme: //              Token: Comment
Line 78: Lexeme: aylist          Token: Noise Word
Line 79: Lexeme: eat             Token: Noise Word
Line 80: Lexeme: put             Token: Noise Word
Line 81: Lexeme: tier            Token: Noise Word
Line 82: Lexeme: tra             Token: Noise Word
Line 83: Lexeme: wise            Token: Noise Word
Line 85: Lexeme: //              Token: Comment
Line 86: Lexeme: //              Token: Comment
Line 87: Lexeme: /*              Token: Comment
Line 89: Lexeme: */              Token: Comment
Line 91: Lexeme: //              Token: Comment
Line 92: Lexeme: ,               Token: Delimiter
Line 93: Lexeme: ;               Token: Delimiter
Line 94: Lexeme: (               Token: Delimiter
Line 95: Lexeme: )               Token: Delimiter
Line 96: Lexeme: {               Token: Delimiter
Line 97: Lexeme: }               Token: Delimiter
Line 98: Lexeme: "               Token: Constant
Line 99: Lexeme: "               Token: Constant
Line 100: Lexeme: [               Token: Delimiter
Line 101: Lexeme: ]               Token: Delimiter
Line 103: Lexeme: //              Token: Comment
Line 104: Lexeme: Valid100        Token: Identifier
Line 105: Lexeme: inv@lid         Token: Invalid
Line 106: Lexeme: Valid_identifier Token: Identifier
Line 107: Lexeme: valid_identifier Token: Identifier
Line 108: Lexeme: _valid1         Token: Identifier
Line 109: Lexeme: #valid2         Token: Identifier
Line 110: Lexeme: 1invalid        Token: Invalid
Line 111: Lexeme: valid#1         Token: Identifier
Line 112: Lexeme: valid__alphabet Token: Identifier
Line 113: Lexeme: invalid##       Token: Invalid
Line 114: Lexeme: test#identifier Token: Identifier
Line 115: Lexeme: va              Token: Identifier
Line 115: Lexeme: lid             Token: Identifier
Line 116: Lexeme: casesensitiveidentifier Token: Identifier
Line 117: Lexeme: CaseSensitiveIdentifier Token: Identifier
Line 118: Lexeme: thisIsInv@_valid1 Token: Invalid
Line 119: Lexeme: ##thisShouldBeValid Token: Identifier
Line 120: Lexeme: beh##           Token: Invalid
Line 121: Lexeme: vibe            Token: Keyword
Line 122: Lexeme: always          Token: Reserved Word
Line 125: Lexeme: //              Token: Comment
Line 126: Lexeme: @               Token: Invalid
Line 127: Lexeme: ..              Token: Invalid
Line 128: Lexeme: 1.01.01         Token: Invalid
Line 130: Lexeme: //              Token: Comment
Line 131: Lexeme: 5               Token: Constant
Line 132: Lexeme: "test"          Token: Constant
Line 133: Lexeme: 5.5             Token: Constant
Line 134: Lexeme: 'h'             Token: Constant
Line 135: Lexeme: 50              Token: Constant
Line 137: Lexeme: /*              Token: Comment
Line 140: Lexeme: */              Token: Comment
Line 142: Lexeme: //              Token: Comment
Line 143: Lexeme: num             Token: Keyword
Line 143: Lexeme: count           	Token: Identifier
Line 143: Lexeme: ;               Token: Delimiter
Line 144: Lexeme: drift           Token: Keyword
Line 144: Lexeme: decimal         Token: Identifier
Line 144: Lexeme: =               Token: Operator
Line 144: Lexeme: 89.70           	Token: Constant
Line 144: Lexeme: ;               Token: Delimiter
Line 145: Lexeme: num             Token: Keyword
Line 145: Lexeme: count           Token: Identifier
Line 145: Lexeme: =               Token: Operator
Line 145: Lexeme: number          	Token: Identifier
Line 145: Lexeme: ;               Token: Delimiter
Line 146: Lexeme: count           Token: Identifier
Line 146: Lexeme: *=              Token: Operator
Line 146: Lexeme: test_number     	Token: Identifier
Line 146: Lexeme: ;               Token: Delimiter
Line 147: Lexeme: iffy            Token: Keyword
Line 147: Lexeme: (               Token: Delimiter
Line 147: Lexeme: average         Token: Identifier
Line 147: Lexeme: >=              Token: Operator
Line 147: Lexeme: 97.90           	Token: Constant
Line 147: Lexeme: )               Token: Delimiter
Line 147: Lexeme: {               Token: Delimiter
Line 148: Lexeme: out             	Token: Keyword
Line 148: Lexeme: (               Token: Delimiter
Line 148: Lexeme: "GWA            Token: Constant
Line 148: Lexeme: is              Token: Identifier
Line 148: Lexeme: very            Token: Identifier
Line 148: Lexeme: high!"          	Token: Invalid
Line 148: Lexeme: )               Token: Delimiter
Line 148: Lexeme: ;               Token: Delimiter
Line 149: Lexeme: }               Token: Delimiter
Line 150: Lexeme: iffy            Token: Keyword
Line 150: Lexeme: (               Token: Delimiter
Line 150: Lexeme: a               Token: Identifier
Line 150: Lexeme: ==              Token: Operator
Line 150: Lexeme: b               	Token: Identifier
Line 150: Lexeme: )               Token: Delimiter
Line 150: Lexeme: {               Token: Delimiter
Line 151: Lexeme: out             	Token: Keyword
Line 151: Lexeme: (               Token: Delimiter
Line 151: Lexeme: "Same!"         	Token: Constant
Line 151: Lexeme: )               Token: Delimiter
Line 151: Lexeme: ;               Token: Delimiter
Line 152: Lexeme: }               Token: Delimiter
Line 152: Lexeme: ex              Token: Keyword
Line 152: Lexeme: (               Token: Delimiter
Line 152: Lexeme: a               Token: Identifier
Line 152: Lexeme: >               Token: Operator
Line 152: Lexeme: b               	Token: Identifier
Line 152: Lexeme: )               Token: Delimiter
Line 152: Lexeme: {               Token: Delimiter
Line 153: Lexeme: out             	Token: Keyword
Line 153: Lexeme: (               Token: Delimiter
Line 153: Lexeme: "Greater!"      	Token: Constant
Line 153: Lexeme: )               Token: Delimiter
Line 153: Lexeme: ;               Token: Delimiter
Line 154: Lexeme: }               Token: Delimiter
Line 154: Lexeme: other           Token: Keyword
Line 154: Lexeme: {               Token: Delimiter
Line 155: Lexeme: out             	Token: Keyword
Line 155: Lexeme: (               Token: Delimiter
Line 155: Lexeme: "Less!"         	Token: Constant
Line 155: Lexeme: )               Token: Delimiter
Line 155: Lexeme: ;               Token: Delimiter
Line 156: Lexeme: }               Token: Delimiter
Line 157: Lexeme: meanwhile       Token: Keyword
Line 157: Lexeme: (               Token: Delimiter
Line 157: Lexeme: i               Token: Identifier
Line 157: Lexeme: <               Token: Operator
Line 157: Lexeme: 5               	Token: Constant
Line 157: Lexeme: )               Token: Delimiter
Line 157: Lexeme: {               Token: Delimiter
Line 158: Lexeme: out             	Token: Keyword
Line 158: Lexeme: (               Token: Delimiter
Line 158: Lexeme: i               	Token: Identifier
Line 158: Lexeme: )               Token: Delimiter
Line 158: Lexeme: ;               Token: Delimiter
Line 159: Lexeme: i++             	Token: Invalid
Line 159: Lexeme: ;               Token: Delimiter
Line 160: Lexeme: }               Token: Delimiter
